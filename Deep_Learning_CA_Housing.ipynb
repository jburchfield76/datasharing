{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPe/CCylkkngpyj6/0EKD9N",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jburchfield76/datasharing/blob/master/Deep_Learning_CA_Housing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_california_housing #diff from book code, ethical concerns with Boston df\n",
        "housing = fetch_california_housing()    #may use Boston in future, along with study links, to understand ethical concerns"
      ],
      "metadata": {
        "id": "K-kPHCJl8_MN"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import scale"
      ],
      "metadata": {
        "id": "VK9x098J9GBn"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = scale(housing.data), housing.target"
      ],
      "metadata": {
        "id": "8SJNTn5b9OAG"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "regression = LinearRegression()\n",
        "regression.fit(X, y)\n",
        "\n",
        "print('R2 %0.3f' % regression.score(X, y))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0js7gu_H9XGe",
        "outputId": "1c034416-558e-4b3a-d6ae-17681b4ce54d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2 0.606\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print([a + ':' + str(round(b, 1)) for a, b in\n",
        "       zip(housing.feature_names, regression.coef_)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qXvD68Kc9u6I",
        "outputId": "55e7e6e3-646e-41c3-afb3-44394ddb2834"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['MedInc:0.8', 'HouseAge:0.1', 'AveRooms:-0.3', 'AveBedrms:0.3', 'Population:-0.0', 'AveOccup:-0.0', 'Latitude:-0.9', 'Longitude:-0.9']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
        "lbl = LabelEncoder()\n",
        "enc = OneHotEncoder()\n",
        "qualitative = ['red', 'red', 'green', 'blue',\n",
        "               'red', 'blue', 'blue', 'green']\n",
        "labels = lbl.fit_transform(qualitative).reshape(8,1)\n",
        "print(enc.fit_transform(labels).toarray())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WIY0TLOF-D-a",
        "outputId": "57534b43-6dd6-4938-b0b6-61c849cec8f7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.model_selection  import train_test_split\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "pf = PolynomialFeatures(degree=2)\n",
        "poly_X = pf.fit_transform(X)\n",
        "X_train, X_test, y_train, y_test = train_test_split(poly_X,\n",
        "                    y, test_size=0.33, random_state=42)\n",
        "\n",
        "from sklearn.linear_model import Ridge #the below comment is changed code from book\n",
        "# The 'normalize' parameter has been removed. If you need to normalize your data,\n",
        "# you should do it before fitting the model using StandardScaler or MinMaxScaler.\n",
        "reg_regression = Ridge(alpha=0.1)\n",
        "reg_regression.fit(X_train,y_train)\n",
        "print ('R2: %0.3f' % r2_score(y_test,reg_regression.predict(X_test)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SVa7Pww0-xxX",
        "outputId": "cd09ff1c-17db-4687-a9e2-6d68509ecf5b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2: 0.659\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "a = np.array([0, 0, 0, 0, 1, 1, 1, 1])\n",
        "b = np.array([1, 2, 3, 4, 5, 6, 7, 8]).reshape(8,1)\n",
        "from sklearn.linear_model import LinearRegression\n",
        "regression = LinearRegression()\n",
        "regression.fit(b,a)\n",
        "print (regression.predict(b)>0.5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yacx-iou_EVR",
        "outputId": "b0d47f6d-bd18-4f12-cc17-4616cfebf199"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[False False False False  True  True  True  True]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Adjust the threshold to create a more balanced binary target variable\n",
        "binary_y = np.array(y >= np.median(y)).astype(int)  # DIFF FROM BOOK VALUE Use median as threshold\n",
        "\n",
        "# Alternatively, explore other ways to create a binary target variable with sufficient samples in each class\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,\n",
        "                                                    binary_y,\n",
        "                                                    test_size=0.33,\n",
        "                                                    random_state=5)\n",
        "logistic = LogisticRegression()\n",
        "logistic.fit(X_train, y_train)\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "print('In-sample accuracy: %0.3f' %\n",
        "      accuracy_score(y_train, logistic.predict(X_train)))\n",
        "print('Out-of-sample accuracy: %0.3f' %\n",
        "      accuracy_score(y_test, logistic.predict(X_test)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ttiSsIM-_u_7",
        "outputId": "423ba27e-212b-4c38-b6cd-712d15066150"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In-sample accuracy: 0.838\n",
            "Out-of-sample accuracy: 0.841\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for var,coef in zip(housing.feature_names,\n",
        "                    logistic.coef_[0]):\n",
        "        print (\"%7s : %7.3f\" %(var, coef))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32GgZbjS_3TW",
        "outputId": "3c44a7f7-f093-4211-8f09-67aecbcc0e37"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " MedInc :   2.479\n",
            "HouseAge :   0.259\n",
            "AveRooms :  -0.800\n",
            "AveBedrms :   0.971\n",
            "Population :   0.131\n",
            "AveOccup :  -5.711\n",
            "Latitude :  -3.632\n",
            "Longitude :  -3.390\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('\\nclasses:',logistic.classes_)\n",
        "print('\\nProbs:\\n',logistic.predict_proba(X_test)[:3,:])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j5Qtw2pvAF4d",
        "outputId": "2562485a-2bcd-4f73-df74-7e26b79e6ba4"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "classes: [0 1]\n",
            "\n",
            "Probs:\n",
            " [[0.69845053 0.30154947]\n",
            " [0.46476874 0.53523126]\n",
            " [0.96476771 0.03523229]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,\n",
        "                y, test_size=0.33, random_state=42)\n",
        "check = [2**i for i in range(8)]\n",
        "for i in range(2**7+1):\n",
        "    X_train = np.column_stack((X_train,np.random.random(\n",
        "        X_train.shape[0])))\n",
        "    X_test = np.column_stack((X_test,np.random.random(\n",
        "        X_test.shape[0])))\n",
        "    regression.fit(X_train, y_train)\n",
        "    if i in check:\n",
        "        print (\"Random features: %i -> R2: %0.3f\" %\n",
        "               (i, r2_score(y_train,regression.predict(X_train))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SQs5WYUwAOwS",
        "outputId": "c71f9e17-cb32-4fe2-d67e-b758674c9f11"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random features: 1 -> R2: 0.609\n",
            "Random features: 2 -> R2: 0.609\n",
            "Random features: 4 -> R2: 0.609\n",
            "Random features: 8 -> R2: 0.610\n",
            "Random features: 16 -> R2: 0.610\n",
            "Random features: 32 -> R2: 0.610\n",
            "Random features: 64 -> R2: 0.611\n",
            "Random features: 128 -> R2: 0.613\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "regression.fit(X_train, y_train)\n",
        "print ('R2 %0.3f'\n",
        "   % r2_score(y_test,regression.predict(X_test)))\n",
        "# Please notice that the R2 result may change from run to\n",
        "# run due to the random nature of the experiment"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "En3LSnBpAiqa",
        "outputId": "6b3797dc-a670-4c25-a712-c3821e8dac2d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2 0.592\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.model_selection import train_test_split #below comment-removed normalize=True from book code\n",
        "from sklearn.preprocessing import StandardScaler # Import StandardScaler for normalization\n",
        "\n",
        "pf = PolynomialFeatures(degree=2)\n",
        "poly_X = pf.fit_transform(X)\n",
        "X_train, X_test, y_train, y_test = train_test_split(poly_X,\n",
        "                    y, test_size=0.33, random_state=42)\n",
        "\n",
        "# Create a StandardScaler instance\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit the scaler on the training data and transform both training and testing data\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "from sklearn.linear_model import Ridge\n",
        "reg_regression = Ridge(alpha=0.1) # Remove normalize=True\n",
        "reg_regression.fit(X_train,y_train)\n",
        "print ('R2: %0.3f'\n",
        "   % r2_score(y_test,reg_regression.predict(X_test)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7DEtChYnBD1x",
        "outputId": "b04bf5ba-a949-4f62-9e4e-0187a232610c"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2: 0.662\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import SGDRegressor\n",
        "\n",
        "# reset X_train, X_test, y_train, y_test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,\n",
        "                    y, test_size=0.33, random_state=42)\n",
        "\n",
        "SGD = SGDRegressor(penalty=None,\n",
        "                   learning_rate='invscaling',\n",
        "                   eta0=0.01, power_t=0.25,\n",
        "                   max_iter=5, tol=None)\n",
        "\n",
        "power = 17\n",
        "check = [2**i for i in range(power+1)]\n",
        "for i in range(400):\n",
        "    for j in range(X_train.shape[0]): #below is changed from book-shape of df is now different\n",
        "        # Reshape using the actual number of features in X_train\n",
        "        SGD.partial_fit(X_train[j,:].reshape(1, X_train.shape[1]),\n",
        "                        y_train[j].reshape(1,))\n",
        "        count = (j+1) + X_train.shape[0] * i\n",
        "        if count in check:\n",
        "            R2 = r2_score(y_test,SGD.predict(X_test))\n",
        "            print ('Example %6i R2 %0.3f coef: %s' %\n",
        "            (count, R2, ' '.join(map(lambda x:'%0.3f' %x, SGD.coef_))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 705
        },
        "id": "HMboAArqB2ZO",
        "outputId": "2e6a8943-d28d-4508-a689-3f80dc2483b5"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example      1 R2 -3.209 coef: -0.018 -0.009 -0.011 0.001 -0.007 -0.001 -0.009 0.008\n",
            "Example      2 R2 -3.112 coef: -0.013 0.001 -0.002 0.000 -0.019 -0.003 0.017 -0.033\n",
            "Example      4 R2 -3.056 coef: -0.019 0.017 -0.007 -0.000 -0.023 -0.000 0.004 -0.022\n",
            "Example      8 R2 -2.937 coef: -0.015 0.006 -0.013 -0.005 0.020 -0.001 0.023 -0.051\n",
            "Example     16 R2 -2.701 coef: -0.035 0.044 -0.023 -0.009 0.003 -0.000 0.017 -0.053\n",
            "Example     32 R2 -2.286 coef: -0.006 0.096 -0.012 -0.009 0.013 -0.006 -0.020 -0.018\n",
            "Example     64 R2 -1.610 coef: 0.151 0.130 0.005 -0.022 -0.001 -0.015 -0.009 -0.053\n",
            "Example    128 R2 -0.938 coef: 0.250 0.167 0.017 -0.029 0.005 -0.024 -0.080 -0.003\n",
            "Example    256 R2 -0.216 coef: 0.412 0.216 0.070 -0.037 0.069 -0.037 -0.116 -0.009\n",
            "Example    512 R2 0.298 coef: 0.579 0.194 0.080 -0.033 0.043 -0.058 -0.134 -0.082\n",
            "Example   1024 R2 0.502 coef: 0.685 0.200 0.036 -0.039 0.043 -0.054 -0.198 -0.135\n",
            "Example   2048 R2 0.547 coef: 0.776 0.204 0.021 0.001 0.049 -0.087 -0.239 -0.250\n",
            "Example   4096 R2 0.571 coef: 0.835 0.190 -0.085 0.055 0.020 -0.140 -0.370 -0.334\n",
            "Example   8192 R2 0.178 coef: 0.766 0.128 -0.133 0.191 -0.133 -5.972 -0.715 -0.518\n",
            "Example  16384 R2 0.247 coef: 0.773 -0.025 -0.111 0.173 -0.253 3.879 -0.875 -0.845\n",
            "Example  32768 R2 -14.714 coef: 1.401 0.599 -1.586 1.262 0.891 -32.478 1.084 1.261\n",
            "Example  65536 R2 -357810.577 coef: -34.978 -31.279 -13.369 -6.850 -34.793 -4835.779 -126.357 -52.991\n",
            "Example 131072 R2 -7694678.715 coef: -699.637 -316.680 314.508 -102.077 -917.943 -20743.938 -600.341 -106.036\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-0cb9fb51da56>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#below is changed from book-shape of df is now different\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;31m# Reshape using the actual number of features in X_train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         SGD.partial_fit(X_train[j,:].reshape(1, X_train.shape[1]),  \n\u001b[0m\u001b[1;32m     19\u001b[0m                         y_train[j].reshape(1,)) \n\u001b[1;32m     20\u001b[0m         \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1387\u001b[0m                 )\n\u001b[1;32m   1388\u001b[0m             ):\n\u001b[0;32m-> 1389\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_stochastic_gradient.py\u001b[0m in \u001b[0;36mpartial_fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1541\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_more_validate_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfor_partial_fit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1543\u001b[0;31m         return self._partial_fit(\n\u001b[0m\u001b[1;32m   1544\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1545\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_stochastic_gradient.py\u001b[0m in \u001b[0;36m_partial_fit\u001b[0;34m(self, X, y, alpha, C, loss, learning_rate, max_iter, sample_weight, coef_init, intercept_init)\u001b[0m\n\u001b[1;32m   1506\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_average_intercept\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"C\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1508\u001b[0;31m         self._fit_regressor(\n\u001b[0m\u001b[1;32m   1509\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_stochastic_gradient.py\u001b[0m in \u001b[0;36m_fit_regressor\u001b[0;34m(self, X, y, alpha, C, loss, learning_rate, sample_weight, max_iter)\u001b[0m\n\u001b[1;32m   1729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1730\u001b[0m         \u001b[0m_plain_sgd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_plain_sgd_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcoef\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1731\u001b[0;31m         coef, intercept, average_coef, average_intercept, self.n_iter_ = _plain_sgd(\n\u001b[0m\u001b[1;32m   1732\u001b[0m             \u001b[0mcoef\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1733\u001b[0m             \u001b[0mintercept\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}